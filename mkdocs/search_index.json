{
    "docs": [
        {
            "location": "/",
            "text": "CFIA OLC Workflow for B\ufe0facterial Assembly and Typing\n\n\nGitHub Repo\n\n\n\n\n\n\nThis pipeline is designed to automatically perform quality control, assemble, and type FASTQ-formatted reads from an Illumina MiSeq",
            "title": "Home"
        },
        {
            "location": "/#cfia-olc-workflow-for-bacterial-assembly-and-typing",
            "text": "GitHub Repo    This pipeline is designed to automatically perform quality control, assemble, and type FASTQ-formatted reads from an Illumina MiSeq",
            "title": "CFIA OLC Workflow for B\ufe0facterial Assembly and Typing"
        },
        {
            "location": "/overview/",
            "text": "Overview",
            "title": "Overview"
        },
        {
            "location": "/overview/#overview",
            "text": "",
            "title": "Overview"
        },
        {
            "location": "/installation/",
            "text": "COWBAT Installation\n\n\nDependencies\n\n\n\n\nLinux system\n\n\nConda\n\n\nDocker\n\n\n\n\nConda method\n\n\nThe way I install conda:\n\n\nwget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\nbash miniconda.sh -b -p $HOME/miniconda\nexport PATH=\"$HOME/miniconda/bin:$PATH\"\nconda config --set always_yes yes\nconda update -q conda\n\n\n\n\nThe easiest way to install COWBAT is to download the source code \nGitHub Link\n\n\ngit clone https://github.com/OLC-Bioinformatics/COWBAT.git\ncd COWBAT\nexport PATH=\"/path/to/repository/COWBAT:$PATH\"\nconda env create -f environment.yml\nsource activate cowbat\n\n\n\n\nDocker method\n\n\nDocker must already be installed\n\n\nThe docker image relies on conda to install all the dependencies, so the cowbat environment must be sourced within \nthe container prior to launch. The supplied command below launches container, and immediately sources the environment, and runs the \npipeline, but it is also possible to run those commands separately from within the container. For additional details on the run\ncommand, please see \nthe tutorial\n.\n\n\ngit clone https://github.com/OLC-Bioinformatics/COWBAT.git\ncd COWBAT\ndocker build -t cowbat:latest .\ndocker run -it --name cowbat --rm cowbat:latest /bin/bash -c \"source activate cowbat && assembly_pipeline.py -s /path/to/sequences -r /path/to/database\"\n\n\n\n\nDatabases\n\n\nUse the database setup script included in OLCTools. This will download and set up all required databases.\n\n\nNOTE: If you want rMLST databases, you must contact Keith Jolley (keith.jolley@zoo.ox.ac.uk)\nfor an account, and for the necessary keys. \n\n\nIMPORTANT NOTE: The \n-c\n flag should be provided with the path to the directory where \nsecret.txt\n is stored,\nnot to the \nsecret.txt\n itself.\n\n\npython -m databasesetup.database_setup -d /PATH/TO/DESIRED/LOCATION -c /PATH/TO/RMLST/CREDENTIALS\n\n\n\n\nTesting\n\n\nUnit tests",
            "title": "Installation"
        },
        {
            "location": "/installation/#cowbat-installation",
            "text": "Dependencies   Linux system  Conda  Docker   Conda method  The way I install conda:  wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\nbash miniconda.sh -b -p $HOME/miniconda\nexport PATH=\"$HOME/miniconda/bin:$PATH\"\nconda config --set always_yes yes\nconda update -q conda  The easiest way to install COWBAT is to download the source code  GitHub Link  git clone https://github.com/OLC-Bioinformatics/COWBAT.git\ncd COWBAT\nexport PATH=\"/path/to/repository/COWBAT:$PATH\"\nconda env create -f environment.yml\nsource activate cowbat  Docker method  Docker must already be installed  The docker image relies on conda to install all the dependencies, so the cowbat environment must be sourced within \nthe container prior to launch. The supplied command below launches container, and immediately sources the environment, and runs the \npipeline, but it is also possible to run those commands separately from within the container. For additional details on the run\ncommand, please see  the tutorial .  git clone https://github.com/OLC-Bioinformatics/COWBAT.git\ncd COWBAT\ndocker build -t cowbat:latest .\ndocker run -it --name cowbat --rm cowbat:latest /bin/bash -c \"source activate cowbat && assembly_pipeline.py -s /path/to/sequences -r /path/to/database\"  Databases  Use the database setup script included in OLCTools. This will download and set up all required databases.  NOTE: If you want rMLST databases, you must contact Keith Jolley (keith.jolley@zoo.ox.ac.uk)\nfor an account, and for the necessary keys.   IMPORTANT NOTE: The  -c  flag should be provided with the path to the directory where  secret.txt  is stored,\nnot to the  secret.txt  itself.  python -m databasesetup.database_setup -d /PATH/TO/DESIRED/LOCATION -c /PATH/TO/RMLST/CREDENTIALS  Testing  Unit tests",
            "title": "COWBAT Installation"
        },
        {
            "location": "/tutorial/",
            "text": "Tutorial\n\n\nBasic settings\n\n\nThe pipeline is designed to run with a minimum of two supplied parameters:\n\n\n* path to FASTQ sequence data (-s)\n* path to reference database (-r)\n\n\n\nThe following command will run the pipeline on the supplied sequences with default parameters\n\n\nassembly_pipeline.py -s /path/to/sequences -r /path/to/database\n\n\n\n\n\nOptional parameters\n\n\nThere are a number of optional parameters than can be supplied to the assembly_pipeline.py script\n\n\n  -h, --help            \n                        show help message and exit\n  -v, --version         \n                        show program's version number and exit\n\n  -n, --numreads NUMREADS\n                        Specify the number of reads. Paired-reads: 2,\n                        unpaired-reads: 1. Default is paired-end\n  -t, --threads THREADS\n                        Number of threads. Default is the number of cores in\n                        the system\n  -c, --customsamplesheet CUSTOMSAMPLESHEET\n                        Path of folder containing a custom sample sheet and\n                        name of sample sheet file e.g.\n                        /home/name/folder/BackupSampleSheet.csv. Note that\n                        this sheet must still have the same format of Illumina\n                        SampleSheet.csv files\n  -b, --basicassembly   \n                        Performs a basic de novo assembly, and does not\n                        collect run metadata\n  -p, --preprocess      \n                        Performs quality trimming and error correction only. Do\n                        not assemble the trimmed + corrected reads",
            "title": "Tutorial"
        },
        {
            "location": "/tutorial/#tutorial",
            "text": "Basic settings  The pipeline is designed to run with a minimum of two supplied parameters:  * path to FASTQ sequence data (-s)\n* path to reference database (-r)  The following command will run the pipeline on the supplied sequences with default parameters  assembly_pipeline.py -s /path/to/sequences -r /path/to/database  Optional parameters  There are a number of optional parameters than can be supplied to the assembly_pipeline.py script    -h, --help            \n                        show help message and exit\n  -v, --version         \n                        show program's version number and exit\n\n  -n, --numreads NUMREADS\n                        Specify the number of reads. Paired-reads: 2,\n                        unpaired-reads: 1. Default is paired-end\n  -t, --threads THREADS\n                        Number of threads. Default is the number of cores in\n                        the system\n  -c, --customsamplesheet CUSTOMSAMPLESHEET\n                        Path of folder containing a custom sample sheet and\n                        name of sample sheet file e.g.\n                        /home/name/folder/BackupSampleSheet.csv. Note that\n                        this sheet must still have the same format of Illumina\n                        SampleSheet.csv files\n  -b, --basicassembly   \n                        Performs a basic de novo assembly, and does not\n                        collect run metadata\n  -p, --preprocess      \n                        Performs quality trimming and error correction only. Do\n                        not assemble the trimmed + corrected reads",
            "title": "Tutorial"
        },
        {
            "location": "/tests/",
            "text": "Tests\n\n\nA test script and test datasets are included in the repository to ensure that installation of the script and dependencies \nwas successful. To run the unit tests (make sure that the cowbat conda environment is active):\n\n\ncd COWBAT\npytest\n\n\n\n\nIf any test fails, check the output to see where the issues occurred",
            "title": "Tests"
        },
        {
            "location": "/tests/#tests",
            "text": "A test script and test datasets are included in the repository to ensure that installation of the script and dependencies \nwas successful. To run the unit tests (make sure that the cowbat conda environment is active):  cd COWBAT\npytest  If any test fails, check the output to see where the issues occurred",
            "title": "Tests"
        },
        {
            "location": "/typing/",
            "text": "",
            "title": "Typing"
        }
    ]
}