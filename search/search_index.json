{
    "docs": [
        {
            "location": "/",
            "text": "CFIA OLC Workflow for B\ufe0facterial Assembly and Typing\n\n\nGitHub Repo\n\n\n\n\nThis pipeline is designed to automatically perform quality control, assemble, and type FASTQ-formatted reads from an Illumina MiSeq",
            "title": "Home"
        },
        {
            "location": "/#cfia-olc-workflow-for-bacterial-assembly-and-typing",
            "text": "",
            "title": "CFIA OLC Workflow for B\ufe0facterial Assembly and Typing"
        },
        {
            "location": "/#github-repo",
            "text": "This pipeline is designed to automatically perform quality control, assemble, and type FASTQ-formatted reads from an Illumina MiSeq",
            "title": "GitHub Repo"
        },
        {
            "location": "/overview/",
            "text": "Overview",
            "title": "Overview"
        },
        {
            "location": "/overview/#overview",
            "text": "",
            "title": "Overview"
        },
        {
            "location": "/installation/",
            "text": "COWBAT Installation\n\n\nDependencies\n\n\n\n\nLinux system\n\n\nConda\n\n\nDocker\n\n\n\n\nConda method\n\n\nThe way I install conda:\n\n\nwget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\nbash miniconda.sh -b -p $HOME/miniconda\nexport PATH=\"$HOME/miniconda/bin:$PATH\"\nconda config --set always_yes yes\nconda update -q conda\n\n\n\n\nThe easiest way to install COWBAT is to download the source code \nGitHub Link\n\n\ngit clone https://github.com/OLC-Bioinformatics/COWBAT.git\ncd COWBAT\nexport PATH=\"/path/to/repository/COWBAT:$PATH\"\nconda env create -f environment.yml\nsource activate cowbat\n\n\n\n\nDocker method\n\n\nDocker must already be installed\n\n\nThe docker image relies on conda to install all the dependencies, so the cowbat environment must be sourced within \nthe container prior to launch. The supplied command below launches container, and immediately sources the environment, and runs the \npipeline, but it is also possible to run those commands separately from within the container. For additional details on the run\ncommand, please see \nthe tutorial\n.\n\n\ngit clone https://github.com/OLC-Bioinformatics/COWBAT.git\ncd COWBAT\ndocker build -t cowbat:latest .\ndocker run -it --name cowbat --rm cowbat:latest /bin/bash -c \"source activate cowbat && assembly_pipeline.py /path/to/sequence -r /path/to/database\"\n\n\n\n\nDatabases\n\n\nUse the database_setup.py script included in the repository. This will download and set up all required databases.\n\n\nNOTE: If you want rMLST databases, you must contact Keith Jolley (keith.jolley@zoo.ox.ac.uk)\nfor an account, and for the necessary keys.\n\n\npython database_setup.py -d /PATH/TO/DESIRED/LOCATION \n\n\n\n\nTesting\n\n\nUnit tests",
            "title": "Installation"
        },
        {
            "location": "/installation/#cowbat-installation",
            "text": "",
            "title": "COWBAT Installation"
        },
        {
            "location": "/installation/#dependencies",
            "text": "Linux system  Conda  Docker",
            "title": "Dependencies"
        },
        {
            "location": "/installation/#conda-method",
            "text": "The way I install conda:  wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\nbash miniconda.sh -b -p $HOME/miniconda\nexport PATH=\"$HOME/miniconda/bin:$PATH\"\nconda config --set always_yes yes\nconda update -q conda  The easiest way to install COWBAT is to download the source code  GitHub Link  git clone https://github.com/OLC-Bioinformatics/COWBAT.git\ncd COWBAT\nexport PATH=\"/path/to/repository/COWBAT:$PATH\"\nconda env create -f environment.yml\nsource activate cowbat",
            "title": "Conda method"
        },
        {
            "location": "/installation/#docker-method",
            "text": "Docker must already be installed  The docker image relies on conda to install all the dependencies, so the cowbat environment must be sourced within \nthe container prior to launch. The supplied command below launches container, and immediately sources the environment, and runs the \npipeline, but it is also possible to run those commands separately from within the container. For additional details on the run\ncommand, please see  the tutorial .  git clone https://github.com/OLC-Bioinformatics/COWBAT.git\ncd COWBAT\ndocker build -t cowbat:latest .\ndocker run -it --name cowbat --rm cowbat:latest /bin/bash -c \"source activate cowbat && assembly_pipeline.py /path/to/sequence -r /path/to/database\"",
            "title": "Docker method"
        },
        {
            "location": "/installation/#databases",
            "text": "Use the database_setup.py script included in the repository. This will download and set up all required databases.  NOTE: If you want rMLST databases, you must contact Keith Jolley (keith.jolley@zoo.ox.ac.uk)\nfor an account, and for the necessary keys.  python database_setup.py -d /PATH/TO/DESIRED/LOCATION",
            "title": "Databases"
        },
        {
            "location": "/installation/#testing",
            "text": "Unit tests",
            "title": "Testing"
        },
        {
            "location": "/tutorial/",
            "text": "Tutorial\n\n\nBasic settings\n\n\nThe pipeline is designed to run with a minimum of two supplied parameters:\n\n\n* path to FASTQ sequence data (-s)\n* path to reference database (-r)\n\n\n\nThe following command will run the pipeline on the supplied sequences with default parameters\n\n\nassembly_pipeline.py -s /path/to/sequences -r /path/to/database\n\n\n\n\n\nOptional parameters\n\n\nThere are a number of optional parameters than can be supplied to the assembly_pipeline.py script\n\n\n  -h, --help            \n                        show help message and exit\n  -v, --version         \n                        show program's version number and exit\n\n  -n, --numreads NUMREADS\n                        Specify the number of reads. Paired-reads: 2,\n                        unpaired-reads: 1. Default is paired-end\n  -t, --threads THREADS\n                        Number of threads. Default is the number of cores in\n                        the system\n  -c, --customsamplesheet CUSTOMSAMPLESHEET\n                        Path of folder containing a custom sample sheet and\n                        name of sample sheet file e.g.\n                        /home/name/folder/BackupSampleSheet.csv. Note that\n                        this sheet must still have the same format of Illumina\n                        SampleSheet.csv files\n  -b, --basicassembly   \n                        Performs a basic de novo assembly, and does not\n                        collect run metadata\n  -p, --preprocess      \n                        Performs quality trimming and error correction only. Do\n                        not assemble the trimmed + corrected reads",
            "title": "Tutorial"
        },
        {
            "location": "/tutorial/#tutorial",
            "text": "",
            "title": "Tutorial"
        },
        {
            "location": "/tutorial/#basic-settings",
            "text": "The pipeline is designed to run with a minimum of two supplied parameters:  * path to FASTQ sequence data (-s)\n* path to reference database (-r)  The following command will run the pipeline on the supplied sequences with default parameters  assembly_pipeline.py -s /path/to/sequences -r /path/to/database",
            "title": "Basic settings"
        },
        {
            "location": "/tutorial/#optional-parameters",
            "text": "There are a number of optional parameters than can be supplied to the assembly_pipeline.py script    -h, --help            \n                        show help message and exit\n  -v, --version         \n                        show program's version number and exit\n\n  -n, --numreads NUMREADS\n                        Specify the number of reads. Paired-reads: 2,\n                        unpaired-reads: 1. Default is paired-end\n  -t, --threads THREADS\n                        Number of threads. Default is the number of cores in\n                        the system\n  -c, --customsamplesheet CUSTOMSAMPLESHEET\n                        Path of folder containing a custom sample sheet and\n                        name of sample sheet file e.g.\n                        /home/name/folder/BackupSampleSheet.csv. Note that\n                        this sheet must still have the same format of Illumina\n                        SampleSheet.csv files\n  -b, --basicassembly   \n                        Performs a basic de novo assembly, and does not\n                        collect run metadata\n  -p, --preprocess      \n                        Performs quality trimming and error correction only. Do\n                        not assemble the trimmed + corrected reads",
            "title": "Optional parameters"
        },
        {
            "location": "/tests/",
            "text": "Tests\n\n\nA test script and test datasets are included in the repository to ensure that installation of the script and dependencies \nwas successful. To run the unit tests (make sure that the cowbat conda environment is active):\n\n\ncd COWBAT\npytest\n\n\n\n\nIf any test fails, check the output to see where the issues occurred",
            "title": "Tests"
        },
        {
            "location": "/tests/#tests",
            "text": "A test script and test datasets are included in the repository to ensure that installation of the script and dependencies \nwas successful. To run the unit tests (make sure that the cowbat conda environment is active):  cd COWBAT\npytest  If any test fails, check the output to see where the issues occurred",
            "title": "Tests"
        },
        {
            "location": "/typing/",
            "text": "",
            "title": "Typing"
        }
    ]
}